{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() # '/home/yanxin'\n",
    "# os.listdir()\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from medicaltorch import datasets as mt_datasets\n",
    "from medicaltorch import models as mt_models\n",
    "from medicaltorch import transforms as mt_transforms\n",
    "from medicaltorch import losses as mt_losses\n",
    "from medicaltorch import metrics as mt_metrics\n",
    "from medicaltorch import filters as mt_filters\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import autograd, optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "cudnn.benchmark = True\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yanxin'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=520# 50的倍数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('U_model_550.pkl')\n",
    "# model = torch.load('U_model_size16_100.pkl')\n",
    "# model = torch.load('./sorted_data_16/U_model_size16_1e04.pkl')\n",
    "model = torch.load(str(epoch)+'U_model_size16_512.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input_file=[]\n",
    "# train_gt_file=[]\n",
    "# test_input_file=[]\n",
    "# test_gt_file=[]\n",
    "# for i in range(120):\n",
    "#     train_input_file.append('/home/yanxin/data_ct/'+str(i)+'Venous_tra_5mm.nii')\n",
    "#     train_gt_file.append('/home/yanxin/data_ct/'+str(i)+'Venous_tra_5mm_roi.nii')\n",
    "# for i in range(120,150):\n",
    "#     test_input_file.append('/home/yanxin/data_ct/'+str(i)+'Venous_tra_5mm.nii')\n",
    "#     test_gt_file.append('/home/yanxin/data_ct/'+str(i)+'Venous_tra_5mm_roi.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_file=[]\n",
    "train_gt_file=[]\n",
    "test_input_file=[]\n",
    "test_gt_file=[]\n",
    "# for i in range(120):\n",
    "#     new_ct_name = str(i) + 'input256' + '.nii'\n",
    "#     new_seg_name = str(i) + 'gt256' + '.nii'\n",
    "\n",
    "#     train_input_file.append('/home/yanxin/testdata/' + new_ct_name)\n",
    "#     train_gt_file.append('/home/yanxin/testdata/' + new_seg_name)\n",
    "for i in range(120,150):\n",
    "    new_ct_name = str(i) + 'input512' + '.nii'\n",
    "    new_seg_name = str(i) + 'gt512' + '.nii'\n",
    "    test_input_file.append('/home/yanxin/testdata/' + new_ct_name)\n",
    "    test_gt_file.append('/home/yanxin/testdata/' + new_seg_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file=[]\n",
    "# gt_file=[]\n",
    "# for i in range(150):\n",
    "#     input_file.append('/home/yanxin/data_ct/'+str(i)+'Venous_tra_5mm.nii')\n",
    "#     gt_file.append('/home/yanxin/data_ct/'+str(i)+'Venous_tra_5mm_roi.nii')\n",
    "# for i in range(120,150):\n",
    "#     test_input_file.append('/home/yanxin/data_ct/'+str(i)+'Venous_tra_5mm.nii')\n",
    "#     test_gt_file.append('/home/yanxin/data_ct/'+str(i)+'Venous_tra_5mm_roi.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_num=[]\n",
    "import SimpleITK as sitk\n",
    "for i in test_gt_file:\n",
    "    ct = sitk.ReadImage(i, sitk.sitkInt16)\n",
    "    ct_array = sitk.GetArrayFromImage(ct)\n",
    "    ct_num.append(ct_array.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 88, 133, 174, 215, 316, 362, 400, 440, 488, 528, 570, 625, 669, 709, 746, 796, 847, 933, 966, 1007, 1043, 1081, 1119, 1155, 1191, 1235, 1281, 1324, 1376]\n"
     ]
    }
   ],
   "source": [
    "endlist=[]\n",
    "a=-1\n",
    "for i in range(len(ct_num)):\n",
    "#     print(ct_num[i])\n",
    "    a=ct_num[i]+a\n",
    "    endlist.append(a)\n",
    "print(endlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "startlist=[0]+[i+1 for i in endlist][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transform = transforms.Compose([\n",
    "#         mt_transforms.Resample(1.6, 1.6),\n",
    "#         mt_transforms.CenterCrop2D((256, 256)),\n",
    "#         mt_transforms.ToTensor(),\n",
    "#         mt_transforms.NormalizeInstance(),\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#         mt_transforms.Resample(1.6, 1.6),\n",
    "#         mt_transforms.CenterCrop2D((256, 256)),\n",
    "#         mt_transforms.ToTensor(),\n",
    "#         mt_transforms.NormalizeInstance(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SimpleITK as sitk\n",
    "# for ct_file in os.listdir(ct_path):\n",
    "\n",
    "#     ct = sitk.ReadImage(os.path.join(ct_path, ct_file), sitk.sitkInt16)\n",
    "#     ct_array = sitk.GetArrayFromImage(ct)\n",
    "\n",
    "#     seg_file = ct_file.replace('volume', 'segmentation')\n",
    "#     seg = sitk.ReadImage(os.path.join(seg_path, seg_file), sitk.sitkInt16)\n",
    "#     seg_array = sitk.GetArrayFromImage(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "#         mt_transforms.Resample(1.6, 1.6),\n",
    "#         mt_transforms.CenterCrop2D((256, 256)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "#         mt_transforms.Resample(1.6, 1.6),\n",
    "#         mt_transforms.CenterCrop2D((256, 256)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "])\n",
    "train_pair_tuple=[]\n",
    "test_pair_tuple=[]\n",
    "# for i in range(120):\n",
    "#     train_pair_tuple.append((input_file[i],gt_file[i]))\n",
    "for i in range(30):\n",
    "    test_pair_tuple.append((test_input_file[i],test_gt_file[i]))\n",
    "\n",
    "# load data\n",
    "# 1dfd83b990ae2d3a4604b239681c9f47\n",
    "# train_dataset = mt_datasets.MRI2DSegmentationDataset(train_pair_tuple,transform=train_transform)\n",
    "test_dataset = mt_datasets.MRI2DSegmentationDataset(test_pair_tuple,transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=32,\n",
    "#                           shuffle=False, pin_memory=True,\n",
    "#                           collate_fn=mt_datasets.mt_collate)\n",
    "\n",
    "val_loader = DataLoader(test_dataset, batch_size=1,\n",
    "                        shuffle=False, pin_memory=True,\n",
    "                        collate_fn=mt_datasets.mt_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析一下为什么刚才dice_loss的计算会出现那么大的偏差。目标图像1才是病灶，其余是0。首先计算公式是没有错误的。这个函数的计算对象是两个矩阵，pred与target。在我们这里，训练时候的计算都是【batchsize*1*256*256】的，后来在计算的时候变成了【1*batchsize*256*256】。\n",
    "# 现在分析一下公式，第一步squeeze(dim=1),这个经过实践发现是如果有连续的1维度，删去最后一个。所以我们那两个基本都是不变的（除非size=1）。分子两个矩阵相乘这一步是数乘，可以看作是两步都为1的话才会计算到。（这个解释了为什么开始第一幅设置为全1 的时候出现了很低的diceloss）\n",
    "# 在往后看的话其实就是求和。分母有个平方，可以同时处理1或者-1。经过检测如果只是0-1图像的话，去掉也无所谓。\n",
    "# a=torch.ones([1,1,1,1,10,1,1,1,1,1,1,10,10,1])\n",
    "# b=a.squeeze(dim=1)\n",
    "# print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Diceloss(pred, target):\n",
    "\n",
    "    pred = pred.squeeze(dim=1)\n",
    "#     print(pred.shape)\n",
    "\n",
    "    # dice系数的定义\n",
    "    dice = 2 * (pred * target).sum(dim=1).sum(dim=1).sum(dim=1) / (pred.pow(2).sum(dim=1).sum(dim=1).sum(dim=1) +\n",
    "                                        target.pow(2).sum(dim=1).sum(dim=1).sum(dim=1) + 1e-5)\n",
    "\n",
    "    # 返回的是dice距离\n",
    "    return (1 - dice).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(preds3D.shape)\n",
    "# print(gt3D.shape)\n",
    "# preds3D.squeeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from time import time\n",
    "\n",
    "# import numpy as np\n",
    "# import SimpleITK as sitk\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.ndimage as ndimage\n",
    "# upper = 200\n",
    "# lower = -200\n",
    "# expand_slice = 6  # 轴向上向外扩张的slice数量\n",
    "# size = 16  # 取样的slice数量\n",
    "# # stride = 1  # 取样的步长\n",
    "# down_scale = 0.5\n",
    "# slice_thickness = 5\n",
    "# for i in range(150):\n",
    "#     ct = sitk.ReadImage('/home/yanxin/data_ct/'+str(i) + 'Venous_tra_5mm.nii', sitk.sitkInt16)\n",
    "#     ct_array = sitk.GetArrayFromImage(ct)\n",
    "\n",
    "#     seg = sitk.ReadImage('/home/yanxin/data_ct/'+str(i) + 'Venous_tra_5mm_roi.nii', sitk.sitkInt16)\n",
    "#     seg_array = sitk.GetArrayFromImage(seg)\n",
    "#     seg_array[seg_array > 0] = 1\n",
    "#     ct_array[ct_array > upper] = upper\n",
    "#     ct_array[ct_array < lower] = lower\n",
    "#     ct_array = ndimage.zoom(ct_array, (ct.GetSpacing()[-1] / slice_thickness, down_scale, down_scale), order=3)\n",
    "#     seg_array = ndimage.zoom(seg_array, (ct.GetSpacing()[-1] / slice_thickness,  down_scale, down_scale), order=0)#也缩小一下吧，看看是否对应\n",
    "#     print(ct_array.shape)\n",
    "#     ct_array=np.reshape(ct_array, (-1,1,256,256))\n",
    "#     seg_array=np.reshape(seg_array, (-1,1,256,256))\n",
    "#     print(ct_array.shape)\n",
    "#     ct_array = torch.from_numpy(ct_array)\n",
    "#     seg_array = torch.from_numpy(seg_array)\n",
    "    \n",
    "#     ct_array = ct_array.type(torch.FloatTensor)\n",
    "#     preds3D = model(ct_array)\n",
    "#     preds3D=preds3D.cpu().detach()\n",
    "#     preds3D = threshold_predictions(preds3D)\n",
    "#     loss = mt_losses.dice_loss(seg_array, preds3D)\n",
    "#     print('mt_losses.dice_loss',loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_perchase(start,end):\n",
    "    global gt3D\n",
    "    global preds3D\n",
    "    input_samples, gt_samples = batch[\"input\"], batch[\"gt\"]# 现在一个batch是1个\n",
    "    var_input = input_samples\n",
    "    var_gt = gt_samples\n",
    "    if i==start:\n",
    "        gt3D=torch.cat((gt3D_0,var_gt),dim=1) \n",
    "    else:\n",
    "        gt3D=torch.cat((gt3D,var_gt),dim=1)\n",
    "    del var_gt\n",
    "#     print(var_input.shape)\n",
    "    preds = model(var_input)\n",
    "    preds=preds.cpu().detach()\n",
    "    del var_input\n",
    "    if i==start:\n",
    "        preds3D=torch.cat((preds3D_0,preds),dim=1) \n",
    "    else:\n",
    "        preds3D=torch.cat((preds3D,preds),dim=1)\n",
    "    del preds\n",
    "    if i==end:\n",
    "#         print(gt3D.shape)\n",
    "        preds3D = threshold_predictions(preds3D)\n",
    "#         preds3D = reverse0_1(preds3D)\n",
    "#         gt3D = reverse0_1(gt3D)\n",
    "#         loss=Diceloss(gt3D, preds3D)\n",
    "#         print('Diceloss',loss.item())\n",
    "#         print(gt3D.sum(dim=1).sum(dim=1).sum(dim=1))\n",
    "        \n",
    "        loss = mt_losses.dice_loss(gt3D, preds3D)\n",
    "        print('mt_losses.dice_loss',loss.item())\n",
    "        losslist.append(loss.item())\n",
    "def threshold_predictions(predictions, thr=0.999):\n",
    "    thresholded_preds = predictions[:]\n",
    "    low_values_indices = thresholded_preds < thr\n",
    "    thresholded_preds[low_values_indices] = 0\n",
    "    low_values_indices = thresholded_preds >= thr\n",
    "    thresholded_preds[low_values_indices] = 1\n",
    "    return thresholded_preds\n",
    "def reverse0_1(predictions,):\n",
    "    predictions[:]=1-predictions[:]\n",
    "#     thresholded_preds = predictions[:]\n",
    "#     thresholded_preds_copy = thresholded_preds.copy()\n",
    "#     low_values_indices = thresholded_preds == 1\n",
    "#     thresholded_preds_copy[low_values_indices] = 0\n",
    "#     low_values_indices = thresholded_preds ==0\n",
    "#     thresholded_preds_copy[low_values_indices] = 1\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证集有30个，观察每个的diceloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt_losses.dice_loss -0.18889451026916504\n",
      "mt_losses.dice_loss -3.690036720627177e-08\n",
      "mt_losses.dice_loss -0.4765967130661011\n",
      "mt_losses.dice_loss -0.6889358758926392\n",
      "mt_losses.dice_loss -0.5816876292228699\n",
      "mt_losses.dice_loss -0.498259037733078\n",
      "mt_losses.dice_loss -0.4507160782814026\n",
      "mt_losses.dice_loss -0.8623737096786499\n",
      "mt_losses.dice_loss -0.5638369917869568\n",
      "mt_losses.dice_loss -0.7436213493347168\n",
      "mt_losses.dice_loss -0.008888257667422295\n",
      "mt_losses.dice_loss -0.4044022560119629\n",
      "mt_losses.dice_loss -0.42108598351478577\n",
      "mt_losses.dice_loss -1.744287381200138e-08\n",
      "mt_losses.dice_loss -0.2587638795375824\n",
      "mt_losses.dice_loss -0.774538516998291\n",
      "mt_losses.dice_loss -0.5568521022796631\n",
      "mt_losses.dice_loss -0.703769326210022\n",
      "mt_losses.dice_loss -0.6833595037460327\n",
      "mt_losses.dice_loss -0.14574237167835236\n",
      "mt_losses.dice_loss -0.6139916777610779\n",
      "mt_losses.dice_loss -0.5816831588745117\n",
      "mt_losses.dice_loss -0.579156756401062\n",
      "mt_losses.dice_loss -0.12049972265958786\n",
      "mt_losses.dice_loss -0.6958317160606384\n",
      "mt_losses.dice_loss -0.5330194234848022\n",
      "mt_losses.dice_loss -0.8239367604255676\n",
      "mt_losses.dice_loss -0.6593475341796875\n",
      "mt_losses.dice_loss -0.5081779956817627\n",
      "mt_losses.dice_loss -0.7333975434303284\n"
     ]
    }
   ],
   "source": [
    "losslist=[]\n",
    "gt3D_0 =torch.zeros(1,1,512,512,)\n",
    "preds3D_0 =torch.zeros(1,1,512,512, )\n",
    "global get3D\n",
    "for i, batch in enumerate(val_loader):\n",
    "    if i<(endlist[0]+1): get_loss_perchase(startlist[0],endlist[0])\n",
    "    elif i<(endlist[1]+1): get_loss_perchase(startlist[1],endlist[1])\n",
    "    elif i<(endlist[2]+1): get_loss_perchase(startlist[2],endlist[2])\n",
    "    elif i < (endlist[3] + 1): get_loss_perchase(startlist[3], endlist[3])\n",
    "    elif i < (endlist[4] + 1): get_loss_perchase(startlist[4], endlist[4])\n",
    "    elif i < (endlist[5] + 1): get_loss_perchase(startlist[5], endlist[5])\n",
    "    elif i < (endlist[6] + 1): get_loss_perchase(startlist[6], endlist[6])\n",
    "    elif i < (endlist[7] + 1): get_loss_perchase(startlist[7], endlist[7])\n",
    "    elif i < (endlist[8] + 1): get_loss_perchase(startlist[8], endlist[8])\n",
    "    elif i < (endlist[9] + 1): get_loss_perchase(startlist[9], endlist[9])\n",
    "    elif i < (endlist[10] + 1): get_loss_perchase(startlist[10], endlist[10])\n",
    "    elif i < (endlist[11] + 1): get_loss_perchase(startlist[11], endlist[11])\n",
    "    elif i < (endlist[12] + 1): get_loss_perchase(startlist[12], endlist[12])\n",
    "    elif i < (endlist[13] + 1): get_loss_perchase(startlist[13], endlist[13])\n",
    "    elif i < (endlist[14] + 1): get_loss_perchase(startlist[14], endlist[14])\n",
    "    elif i < (endlist[15] + 1): get_loss_perchase(startlist[15], endlist[15])\n",
    "    elif i < (endlist[16] + 1): get_loss_perchase(startlist[16], endlist[16])\n",
    "    elif i < (endlist[17] + 1): get_loss_perchase(startlist[17], endlist[17])\n",
    "    elif i < (endlist[18] + 1): get_loss_perchase(startlist[18], endlist[18])\n",
    "    elif i < (endlist[19] + 1): get_loss_perchase(startlist[19], endlist[19])\n",
    "    elif i < (endlist[20] + 1): get_loss_perchase(startlist[20], endlist[20])\n",
    "    elif i < (endlist[21] + 1): get_loss_perchase(startlist[21], endlist[21])\n",
    "    elif i < (endlist[22] + 1): get_loss_perchase(startlist[22], endlist[22])\n",
    "    elif i < (endlist[23] + 1): get_loss_perchase(startlist[23], endlist[23])\n",
    "    elif i < (endlist[24] + 1): get_loss_perchase(startlist[24], endlist[24])\n",
    "    elif i < (endlist[25] + 1): get_loss_perchase(startlist[25], endlist[25])\n",
    "    elif i < (endlist[26] + 1): get_loss_perchase(startlist[26], endlist[26])\n",
    "    elif i < (endlist[27] + 1): get_loss_perchase(startlist[27], endlist[27])\n",
    "    elif i < (endlist[28] + 1): get_loss_perchase(startlist[28], endlist[28])\n",
    "    elif i < (endlist[29] + 1): get_loss_perchase(startlist[29], endlist[29])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dice_loss的一些统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.49537888120706536\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(losslist))\n",
    "# print(np.max(losslist))\n",
    "# print(np.min(losslist))\n",
    "# print(np.std(losslist))\n",
    "#550\n",
    "# -0.5144157908650248\n",
    "# -8.795073824785504e-08\n",
    "# -0.9419780969619751\n",
    "# 0.32080316267711895\n",
    "#1300\n",
    "# -0.5176453462473692\n",
    "# -2.3310018093525287e-07\n",
    "# -0.935321033000946\n",
    "# 0.3239882057457576\n",
    "#sort16 100  #这个居然表现不一致，不过想一想230轮确实ta\n",
    "# 这个采样之后表现不一致的解释，就是对没有病的那些图片不能充分学习，都看成了有病的，所以采样率要提升\n",
    "# -0.44041477211152935\n",
    "# -1.9379839955036005e-07\n",
    "# -0.8532313108444214\n",
    "# 0.27906281110196524\n",
    "#sort16 230\n",
    "# -0.4890719051486059\n",
    "# -2.4330893211299554e-07\n",
    "# -0.7980189919471741\n",
    "# 0.2549805772882429\n",
    "#sort16 500 1E04\n",
    "# -0.4737533453806435\n",
    "# -2.4330893211299554e-07\n",
    "# -0.8478531837463379\n",
    "# 0.2665796454403776\n",
    "#sort16 150 1E04\n",
    "# -0.5472723477884576\n",
    "# -2.141327115623426e-07\n",
    "# -0.8840871453285217\n",
    "# 0.28079788497351005\n",
    "#sort16 200 1E04\n",
    "# -0.5661413162339097\n",
    "# -2.0618551843654132e-07\n",
    "# -0.8950169086456299\n",
    "# 0.2827369643951482\n",
    "#sort16 300 1E04\n",
    "# -0.5762936150616108\n",
    "# -1.6556288073843461e-07\n",
    "# -0.9153534770011902\n",
    "# 0.2830451183270229\n",
    "#sort16 1000 1E04\n",
    "# -0.5441274456479097\n",
    "# -2.4330893211299554e-07\n",
    "# -0.908866822719574\n",
    "# 0.285619097358927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(val_loader):\n",
    "#     if i<40:\n",
    "#         endlist\n",
    "#         print(i)\n",
    "        #     print(i,batch.shape)\n",
    "    input_samples, gt_samples = batch[\"input\"], batch[\"gt\"]# 现在一个batch是四个\n",
    "    var_input = input_samples.cuda()\n",
    "    var_gt = gt_samples.cuda()\n",
    "    preds = model(var_input)\n",
    "    preds = threshold_predictions(preds)\n",
    "#         preds = reverse0_1(preds)\n",
    "#         var_gt = reverse0_1(var_gt)\n",
    "#     preds = model(input_samples)\n",
    "#         print(preds)\n",
    "    aa=var_input.cpu().detach().numpy()\n",
    "    a=preds.cpu().detach().numpy()\n",
    "#         print(a.shape)\n",
    "    b=var_gt.cpu().detach().numpy()\n",
    "    if b[0][0].max()==1 or a[0][0].max()==1:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "    #         print(a[0].shape)\n",
    "    #         print(b.shape)\n",
    "    #         print(a[0][0])\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(aa[0][0],cmap='gray')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(marked_roi(aa[0][0],a[0][0],b[0][0]))\n",
    "#             plt.subplot(2,2,3)\n",
    "#             plt.imshow(b[0][0],cmap='gray')# gt\n",
    "#             plt.subplot(2,2,4)\n",
    "#             plt.imshow(a[0][0],cmap='gray')# preds\n",
    "#             plt.subplot(2,2,4)\n",
    "#             plt.imshow(marked_roi(aa[0][0],a[0][0],b[0][0]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, measure, draw,color\n",
    "import skimage\n",
    "# from parallel import parallel_process, agg_results\n",
    "from multiprocessing import Manager\n",
    "# from config import Config\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "def marked_roi(image, mask_pred,mask_gt):\n",
    "    _min = image.min()\n",
    "    _max = image.max()\n",
    "    image = (image - _min) / (_max - _min)\n",
    "    image = skimage.color.gray2rgb(image)\n",
    "    contour_gt = measure.find_contours(mask_gt, 0)\n",
    "    contour_pred = measure.find_contours(mask_pred, 0)\n",
    "    print(len(contour_gt))\n",
    "    print(len(contour_pred))\n",
    "    if len(contour_gt)==0 and len(contour_pred)==0:\n",
    "        return image\n",
    "    if len(contour_gt) >= 1:\n",
    "        for gt_lk in contour_gt:\n",
    "            contour_pixel_gt = (np.array([int(c[0]) for c in gt_lk]), np.array([int(c[1]) for c in gt_lk]))\n",
    "#             marked = image.copy()\n",
    "            image[contour_pixel_gt] = [1, 0, 0] # 目标是红\n",
    "    if len(contour_pred) >= 1:\n",
    "        for pred_lk in contour_pred:\n",
    "            contour_pixel_pred = (np.array([int(c[0]) for c in pred_lk]), np.array([int(c[1]) for c in pred_lk]))\n",
    "#             marked = marked.copy()\n",
    "            image[contour_pixel_pred] = [0, 0, 1]\n",
    "#         contour_pixel_pred = (np.array([int(c[0]) for c in contour_pred[0]]), np.array([int(c[1]) for c in contour_pred[0]]))\n",
    "#     print(len(contour_pixel))\n",
    "#         marked[contour_pixel_pred] = [1, 0, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
